---
title: "Matrices"
author: Szymon Talaga
date: "21.04.2020"
output: html_notebook
---

![](zip.png)

<hr>

```{r setup}
# Default notebook formatting           
knitr::opts_chunk$set(
    fig.width = 5,
    fig.asp = 1,
    fig.align = "center"
)
```

## Introduction

In this notebook we do a brief review of the main functionalities in `R` related to matrices and linear algebra.

## Creating matrix objects

The first thing we need to establish is how to create matrices in `R`. Matrices like vectors are atomic objects,
so they store only one data type (and support efficient, vectorized computations). In fact, internally they
are just vectors with additional metadata that specifies how many rows and columns they have. This also means
that the standard way to initialize a matrix is to convert a vector of values into a matrix.

By default we just provide a vector of values to a constructor function `matrix` and specify the number of rows
or columns (the second value may be automatically inferred). We also need to decide whether the matrix should
be filled in with values by rows or columns (by columns is the default behavior in `R`).

Below we will create the following matrix:

$$
\mathbf{A} =
\begin{pmatrix}
    1 & 2 \\
    3 & 4 \\
    0 & 5
\end{pmatrix}
$$

```{r matrix_init}
## BY COLUMN
A1 <- matrix(c(1, 3, 0, 2, 4, 5), ncol = 2, byrow = FALSE)

## BY ROW
A2 <- matrix(c(1, 2, 3, 4, 0, 5), ncol = 2, byrow = TRUE)

print(A1)
all.equal(A1, A2)
```

However, the approach above is not very readable in the general case. Thus, I recommend to always provide data by row
and use the following formatting:

```{r matrix_init2}
A <- matrix(c(
    1, 2,
    3, 4,
    0, 5
), ncol = 2, byrow = TRUE)
A
```

We can of course use the matrix machinery to create row and column vectors such as:

$$
\mathbf{x} = (0, 5, 3) \qquad \mathbf{y} = \begin{pmatrix}1 \\ 4 \\ 6 \\ 8\end{pmatrix}
$$

```{r row_and_column_vectors}
x <- matrix(c(0, 5, 3), nrow = 1)
cat("x =", x)

y <- matrix(c(1, 4, 6, 8), ncol = 1)
cat("\ny =", y)
```


## Operations on matrices

Matrices are vector-like objects so standard arithmetic operations are fully vectorized over matrices. This means
that arithmetic operators in `R` do not really implement proper matrix operation in terms of linear algebra but
rather generic vectorized arithmetic operations over array. In particular, standard multiplication between two
matrices in `R` is not the saem thing as matrix multiplication.

### Vectorized arithmetic operations

We start by reviewing the generic vectorized arithmetic over matrix objects. We will use the three following matrices:

$$
\mathbf{X} =
\begin{pmatrix}
    1 & 2 \\
    2 & 1
\end{pmatrix}
\qquad
\mathbf{Y} = 
\begin{pmatrix}
    0 & 3 \\
    2 & 4
\end{pmatrix}
\qquad
\mathbf{Z} =
\begin{pmatrix}
    1 & 2 \\
    0 & 1 \\
    1 & 3
\end{pmatrix}
$$

```{r xyz_matrices}
X <- matrix(c(
    1, 2,
    2, 1
), ncol = 2, byrow = TRUE)

Y <- matrix(c(
    0, 3,
    2, 4
), ncol = 2, byrow = TRUE)

Z <- matrix(c(
    1, 2,
    0, 1,
    1, 3
), ncol = 2, byrow = TRUE)
```

Matrix addition seems to work normally. We can add matrices with the same shapes.

```{r matrix_addition1}
X + Y
```

And we fail to add two matrices with different shapes.

```{r matrix_addition2}
X + Z
```

We should only be careful when we add one-dimensional vectors to matrices, because `R` will always execute this
operation even if it does not make too much sense. However, in weird cases it will usually throw a warning.

```{r matrix_addition3}
X + c(1, 2, 3)
```

We can use this to easily perform a basic operation of adding a constant value to all entries in a matrix which is not 
as easy to define in terms of matrix operation in linear algebra.

```{r matrix_addition4}
X + 5
```

Matrix can be also multiplied by a scalar value:

```{r matrix_scalar_mult1}
X * 10
```

But note that `R` will also try to execute a vectorized multiplication between a matrix and a vector, which is
not the same as matrix-vector multiplication in linear algebra.

```{r matrix_scalar_mult2}
X
X * c(1, 4)
```

We see on the example above that `R` aligned vector so each row was multiplied by a different value. However,
with a longer vector of $4$ elements we get:

```{r matrix_scalar_mult3}
X * 1:4
```

We see that `R` aligns the vector along the first column and the along the second column.

Last but not least, we can try to multiply two matrices. In `R` standard multiplication between two matrices
is element-wise.

```{r matrix_mult1}
X * Y
```

But we can not multiply out matrices with different shapes.

```{r matrix_mult2}
X * Z
```

In general, we can apply to matrices any standard operator that we can apply to vectors and it will be applied
elementwise and vectorized column-by-column.


## Matrix operations

Now, once we are aware of the quirks of `R` with respect to matrices we can introduce functions implementing
proper matrix and vector operations.

### Matrix-matrix multiplication

Matrix-matrix multiplication is provided by a special matrix-multiplication operator `%*%`. Let us try to multiply
`X` and `Y` matrices.

```{r mat_mat_mult1}
X %*% X
```

We can easily check by hand that it worked correctly. We can also see that `R` will throw an error
if we try to multiply matrices that are not conformable with respect to matrix-matrix multiplication.

```{r mat_mat_mult2}
X %*% Z
```

This is also a good moment to convince ourselves that matrix-matrix multiplication is not commutative.
We just saw that $\mathbf{XZ}$ multiplication is not even defined. At the same time we can do $\mathbf{ZX}$
without a problem.

```{r mat_mat_mult3}
Z %*% X
```

This makes sense since $\mathbf{X} \in \mathbb{R}^{2 \times 2}$ and $\mathbf{Z} \in \mathbb{R}^{3 \times 2}$.


### Matrix-vector multiplication

Matrix vector multiplication can done with the matrix multiplication operator `%*%`. For a vector we can use
a row or column vector represented as a `matrix` object or simply a one-dimensional vector object which will be
automatically interpreted as a column vector.


```{r mat_vec_mult1}
x1 <- c(1, 2)
x2 <- matrix(x1, ncol = 1)

X %*% x1
X %*% x2
```

Clearly, we got the same results in both cases.


### Inner and outer product of two vectors

We can use matrix multiplication operator `%*%` to compute inner and outer products of two vectors. Consider:

$$
\mathbf{x} = (1, 4, 7) \qquad \mathbf{y} = (5, 11, 3)
$$

If we take just two simple vector objects and try to multiply them with `%*%` this operation will be interpreted as
a dot product (inner product), that is, for `x %*% y` the interpretation will be:
$$
\mathbf{x}^\top\mathbf{y}
$$



```{r inner_product}
x <- c(1, 4, 6)
y <- c(5, 11, 3)

x %*% y
```

This approach may not be very convenient because the output is not a single scalar (vector of length $1$),
but a $1$-by-$1$ matrix. Thus, it is often better to compute dot products just with simple vector operations:

```{r dot_product}
sum(x * y)
```

To compute outer product we have to be more explicit about dimensions and convert the first vector to a column
vector and the second vector to a row vector.

One way to do that is to convert two vector objects to `matrix` objects explicitly.

```{r outer_product}
x_mat <- matrix(x, ncol = 1)
y_mat <- matrix(y, nrow = 1)

x_mat
y_mat


## OUTER PRODUCT
x_mat %*% y_mat
```

There is also a conveniet helper function called `outer`. It takes two vector arguments and compute their outer
product.

```{r outer_product2}
outer(x, y)
```

It can also compute ''outer products'' with different functions (any functions with two arguments will do).
However, those different ''outer products'' are not directly related to linear algebra, so we will not discuss
this issue anymore.


### Transposition

A matrix can be transposed with `t()` function.

```{r transpose}
Z
t(Z)
```

### Diagonal and trace

`R` provides a very convenient function named `diag`. It can be used in two different ways.
If it is called with a square matrix as an argument it extracts its diagonal and returns it as
a vector.

```{r diag1}
diag(X)
```

It also does not throw an error for non-square matrices, but just return as much diagonal elements as possible.
Study the example below to understand what exactly happens in this case.

```{r diag2}
diag(Z)
```

When called with a vector, `diag` creates a diagonal matrix with provided values along the main diagonal.
For instance, it can be used to easily create identity matrices.

```{r identity_matrix}
diag(rep(1, 5))
```

It can be also used to easily implement the trace operator.

```{r trace}
sum(diag(Y))
```

### Determinant

`R` provides also a function for efficient calculations of determinants of square matrices (function `det`).

```{r determinant1}
det(X)
```

It of course throws an error for non-square matrices:

```{r determinant2}
det(Z)
```

Let us check that determinant is really zero for a matrix with dependent rows/columns.

```{r singular-matrix}
U <- matrix(c(
    1, 2,
    2, 4
), byrow = TRUE, ncol = 2)
U
```

Columns and rows of the matrix `A` above are clearly dependent, so its determinant should be exaclty zero.

```{r}
det(U)
```

And it checks out. It also means that it should be invertible. A matrix can be inverted in `R` with `solve` function
called with it as a first argument.

Let us now use `solve` function on the `U` matrix.

```{r invert1}
solve(U)
```

We get an error that the system is singular (non-invertible), which makes sense since we know it should.

Let us now invert and invertible matrix `X`.

```{r invert2}
solve(X)
```

We got some result. But is it really correct?

```{r invert2_check}
solve(X) %*% X
```

Great! We see it works. The product of the inverted and the original matrix is just an identity matrix.

Last but not least, we can also use `R` to solve systems of linear equations. Let us try to solve the simple
system used as an example in the textbook.

$$
\begin{matrix}
    2x_1 + 5x_2 = 3 \\
    x_1 + 2x_2 = 4
\end{matrix}
$$

```{r linear_system}
X <- matrix(c(
    2, 5,
    1, 2
), ncol = 2, byrow = TRUE)

y <- c(3, 4)

## 
bhat <- solve(X) %*% y
bhat
```

We got some values. Are they really correct?

```{r linear_system_check}
all.equal(as.vector(X %*% bhat), y)
```

We can also use a more convenient interface provided by function `solve` when we call it with two arguments.
The first argument has to be a coefficient matrix and the second value the expected results.

```{r linear_system_solve}
solve(X, y)
```

We see we got the same value.
