{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core concepts in statistics\n",
    "\n",
    "Szymon Talaga | 15 March 2020\n",
    "\n",
    "![ZIP logo](zip.png)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will learn how to work in `R` with some the basic statistical concepts such as probability distributions, quantiles, confidence intervals and hypothesis test. A basic familiarity with `R` is assumed. Refer to the auxiliary notebooks with an introduction to `R` if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidyverse\n",
    "\n",
    "In this class we will usually prefer so-called _Tidyverse_ packages and tools over tha base `R`. The reason is that code written with the _Tidyverse_ packages\n",
    "is almost always easier to read and understand. Moreover, some of the main ideas used in these packages are relatively similar to how packages in the `Python`\n",
    "ecosystem, such as _Numpy_ or _Pandas_, are designed.\n",
    "\n",
    "In general we will use mostly two _Tidyverse_ packages: `dplyr` and `ggplot2`. The former will be used for processing data frames\n",
    "(rectangular datasets with observations in rows and variables in columns) and the latter for data visualization.\n",
    "\n",
    "You can read more about the _Tidyverse_ ecosystem [here](https://www.tidyverse.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to run the command below to install some missing packages\n",
    "# Tidyverse package should be installed in Google Colab environments \n",
    "#\n",
    "# install.packages(c(\"BSDA\", \"latex2exp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages that we will need\n",
    "library(tidyverse)    # read in core tidyverse packages at once\n",
    "library(BSDA)         # some helper functions for working with z tests\n",
    "library(latex2exp)    # for easy math on plots\n",
    "\n",
    "# Set default theme for ggplot2\n",
    "theme_set(theme_bw())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipe operator `%>%` and stream processing\n",
    "\n",
    "We will often use a special kind of symbol `%>%`. It is called the pipe operator and it is used to pass value from the left side as the first argument\n",
    "to the function on the right side. For instance, the two expressions below are equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- 1:10\n",
    "\n",
    "## Without the pipe\n",
    "class(mean(x))\n",
    "\n",
    "## With the pipe\n",
    "x %>% \n",
    "    mean %>%\n",
    "    class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Can also do this\n",
    "x %>% mean(na.rm = TRUE)\n",
    "## to pass additional arguments to methods down the chain.\n",
    "\n",
    "## The above is equivalent to:\n",
    "mean(x, na.rm = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipe operator is implemented in `magrittr` package. You can find a short introduction [here](https://magrittr.tidyverse.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ggplot2`\n",
    "\n",
    "For plotting we will usually use the `ggplot2` package. You can read more about it [here](https://ggplot2.tidyverse.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability distributions\n",
    "\n",
    "We start by learning about probability distributions. We discussed this concept quite extensively on the theoretical level in the textbook and here we will\n",
    "try to build more of a practical, hands-on understanding. The focus will be on the difference between probability mass and probability density functions\n",
    "(discrete and continuous random variables) as well as cumulative distribution and quantile functions. Of course we will also talk quite a bit about normal\n",
    "distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general in R, there is a well defined set of functions for working with probability distributions. In general for any probability distribution\n",
    "there are the following function:\n",
    "\n",
    "* `d<name>`: compute PMF/PDF values.\n",
    "* `p<name>`: compute CDF values.\n",
    "* `q<name>`: compute quantile values.\n",
    "* `r<name>`: generate pseudo-random numbers.\n",
    "\n",
    "Where `<name>` stands for an abbreviated name of a distribution. For instance, for normal distributions we have:\n",
    "\n",
    "* `dnorm`: compute normal PDF valeus (probability density).\n",
    "* `pnorm`: compute normal CDF.\n",
    "* `qnorm`: compute normal quantiles.\n",
    "* `rnorm`: generate psudo-random normal numbers.\n",
    "\n",
    "**NOTE.** Remember that you can aways access extensive documentation of almost any `R` function using\n",
    "the `?` operator. For instance, if you want to learn how to sample from normal distribution you can just\n",
    "write `?rnorm` in the console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability mass function (PMF) [discrete variables]\n",
    "\n",
    "Probability mass functions are used to define probability distributions over outcomes of discrete random variables. They are called mass functions because\n",
    "they assign probabilities to particular discrete points as if they were abstract points with point masses (a sort of abstraction often used in physics).\n",
    "This is their characteristic feature because as we will soon see for continuous variables probabilities can be defined only for proper ranges of points\n",
    "and never for individual points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will work a little with the PMF of Poisson distribution. So  if $X$ is a random variables with Poisson distribution with parameter $\\lambda$ then its\n",
    "PMF denoted by $p_X(x)$ is:\n",
    "\n",
    "$$\n",
    "p_X(x) = \\frac{\\lambda^x e^{-\\lambda}}{x!}\n",
    "$$\n",
    "\n",
    "So the above function defines the probability that a realization of a random variable $X$ with Poisson distribution with a parameter $\\lambda$ will be\n",
    "exactly $x$.\n",
    "\n",
    "Poisson distribution is defined for all non-negative integers ($\\mathbb{N}_0$). Its important feature is that $\\mathbb{E}[X] = \\lambda$ and\n",
    "$\\text{Var}[X] = \\lambda$. Poisson distributions are important because they often arise naturally in the context of discrete count variables, that is\n",
    "random variables measuring numbers of occurrences of some objects (negative numbers are not possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we draw PMF of a Poisson distribution with lambda = 5\n",
    "## We will limit X values to the range 0:20\n",
    "lambda <- 5\n",
    "x <- 0:20\n",
    "\n",
    "data <- data.frame(\n",
    "    x = x,\n",
    "    p = dpois(x, lambda = lambda)\n",
    ")\n",
    "\n",
    "data %>%\n",
    "    ggplot(aes(x = x, y = p)) +\n",
    "    geom_segment(aes(x = x, y = 0, xend = x, yend = p)) +\n",
    "    geom_point(color = \"red\", size = 5) +\n",
    "    xlab(\"x\") +\n",
    "    ylab(\"Pr(X = x)\") +\n",
    "    ggtitle(TeX(\"Poisson PMF with $\\\\lambda$ = 5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above representation of the PMF is proper because it emphasizes that $\\Omega_X$ contains only integer values.\n",
    "Similarily, we can represent the CDF of a Poisson variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can use the previous `data` object\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## And just add a new column with CDF values based on `x`\n",
    "data$cdf <- ppois(data$x, lambda = lambda)\n",
    "\n",
    "## And now we can visualize\n",
    "data %>%\n",
    "    ggplot(aes(x = x, y = cdf)) +\n",
    "    geom_point(color = \"red\", size = 5) +\n",
    "    xlab(\"X\") +\n",
    "    ylab(TeX(\"Pr($X \\\\leq x$)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that again, we do not join the points with lines to emphasize the fact that this a discrete distribution. The CDF clearly show that almost all values\n",
    "samples from the distribution will be not greater than $10$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the crucial thing one has to remember about probability mass functions and discrete variables is that we have the following equality:\n",
    "\n",
    "$$\n",
    "\\text{CDF}_X(x) = \\text{Pr}(X \\leq x) = \\sum_{x_0 \\leq k \\leq x}p_X(k)\n",
    "$$\n",
    "\n",
    "where $X$ is a discrete random variable with the probability mass function $p_X(x)$ and $x_0$ is the minimum value in $\\Omega_X$.\n",
    "\n",
    "So in other words we can always recreate CDF by just adding up values of PMF. As we will see this is not as easy in the case of probability density functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability density function (PDF) [continuous]\n",
    "\n",
    "Probability density functions define probability distributions over outcomes of continuous random variables such as normally distributed variables.based \n",
    "Now we will try to understand them based on the normal PDF.\n",
    "\n",
    "From now on we will denote PMFs by $p_X(x)$ and PDFs by $f_X(x)$ to avoid confusion.\n",
    "\n",
    "PDF of a normal random variables with mean $\\mu$ and variance $\\sigma^2$ is defined as:\n",
    "\n",
    "$$\n",
    "f_X(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{n}(\\frac{x - \\mu}{\\sigma})^2}\n",
    "$$\n",
    "\n",
    "In the textbook we always use the parametrization in terms of mean $\\mu$ and variance $\\sigma^2$.\n",
    "However, sometime standard deviation $\\sigma$ is used instead of variance $\\sigma^2$.\n",
    "For instance, this is the parametrization used in `R`. Of course, this choice does not change anything\n",
    "except for the notation, but one should remember about it when using software packages because it is\n",
    "easy to pass a wrong number accidentally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crucial thing is that values of $f_X(x)$ are not probabilities but a special quantities called probability densities. In the case of discrete variables\n",
    "we use the notion of mass, because single point corresponds to particular probabilities (i.e. they have mass). In the case of continuous variables\n",
    "individual points do not have masses but only densities and to get a mass (probability) we have to integrate densities over a range of contiguous points.\n",
    "\n",
    "Thus for a continuous random variable we always have that:\n",
    "\n",
    "$$\n",
    "\\text{Pr}(X = x) = 0\n",
    "$$\n",
    "for any $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilities are well-defined only for events such as:\n",
    "\n",
    "$$\n",
    "\\text{Pr}(x_0 \\leq X \\leq x_1) = \\int_{x_0}^{x_1}f_X(x)dx = \\text{CDF}_X(x_1) - \\text{CDF}_X(x_0)\n",
    "$$\n",
    "\n",
    "This is exactly why it is important that we can easily compute CDFs when working with continuous random variables. Thanks to this we do not have to compute\n",
    "integrals all the time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot (standard) normal PDF to understand this concepts better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- seq(-4, 4, length.out = 100) # you need many points to get a smooth line on a plot\n",
    "\n",
    "data <- data.frame(\n",
    "    x = x,\n",
    "    density = dnorm(x, mean = 0, sd = 1)\n",
    ")\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pdf <- data %>%\n",
    "    ggplot(aes(x = x, y = density)) +\n",
    "    geom_line() +\n",
    "    xlab(\"x\") +\n",
    "    ylab(TeX(\"Probability density $f_X(x)$\")) +\n",
    "    ggtitle(\"Standard normal PDF\")\n",
    "\n",
    "## I saved the plot as a variable for later use\n",
    "## Now I just print it to plot it under the chunk\n",
    "norm_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A single point has probability 0\n",
    "norm_pdf +\n",
    "    geom_segment(x = -1, y = 0, xend = -1, yend = dnorm(-1), color = \"darkred\") +\n",
    "    geom_point(x = -1, y = dnorm(-1), color = \"red\", size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A range of points has a well-defined probability\n",
    "rng <- data.frame(x = c(-1, 1))\n",
    "\n",
    "\n",
    "norm_pdf +\n",
    "    geom_area(data = data.frame(x = seq(-1, 1, length.out = 100)), aes(x = x, y = dnorm(x)), fill = \"red\", alpha = .5) +\n",
    "    geom_segment(data = rng, aes(x = x, y = 0, xend = x, yend = dnorm(x)), color = \"darkred\") +\n",
    "    geom_point(data = rng, aes(x = x, y = dnorm(x)), color = \"red\", size = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The area under the curve for the selected segment above is equal to the difference between two particular\n",
    "points along the standard normal CDF $\\Phi(x)$.\n",
    "\n",
    "$$\n",
    "\\Phi(1) - \\Phi(-1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- seq(-4, 4, length.out = 100)\n",
    "\n",
    "data <- data.frame(x = x)\n",
    "\n",
    "data %>%\n",
    "    ggplot(aes(x = x, y = pnorm(x))) +\n",
    "    geom_line() +\n",
    "    geom_point(data = data.frame(x = c(-1, 1)), aes(x = x, y = pnorm(x)), color = \"red\", size = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile functions\n",
    "\n",
    "In this section we just remind ourselves that quantile functions are inverses of CDFs.\n",
    "\n",
    "For instance if $\\Phi(x)$ is the standard normal CDF then $\\Phi{-1}(p)$ is the standard normal quantile\n",
    "function.\n",
    "\n",
    "So we have that:\n",
    "\n",
    "$$\n",
    "\\Phi^{-1}(\\Phi(x)) = x\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can check this in R\n",
    "2 %>%\n",
    "    pnorm %>%\n",
    "    qnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from a distribution\n",
    "\n",
    "As we already discussed we can sample easily from all probability distributions implemented in `R`.\n",
    "For instance, to sample from a normal distribution we use `rnorm` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate 100 normal variates with mean = 100 and standard deviation (sd) = 15\n",
    "x <- rnorm(100, mean = 100, sd = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Draw simple histogram of values\n",
    "ggplot(data = data.frame(x = x), aes(x = x)) + \n",
    "    geom_histogram(color = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We binned values into 30 bins (selected automatically). Maybe that is too high a resolution for a sample of only\n",
    "$100$ data points. That is why we get a shape which is not very similar to the Bell curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Draw simple histogram of values with 10 bins\n",
    "ggplot(data = data.frame(x = x), aes(x = x)) + \n",
    "    geom_histogram(bins = 10, color = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that sampling will generate different results every time. So:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 <- rnorm(100)\n",
    "x2 <- rnorm(100)\n",
    "\n",
    "all.equal(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can force our pseudo-random generators to yield the same values by setting the random seed to\n",
    "a particular value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(101)\n",
    "x1 <- rnorm(100)\n",
    "set.seed(101)\n",
    "x2 <- rnorm(100)\n",
    "\n",
    "all.equal(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals\n",
    "\n",
    "Later on we will learn about functions and packages that will make it a breeze to run statistical tests\n",
    "and compute confidence intervals. However, first we need to build proper understanding of the main concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the chunk below we will generate some random normal data and compute a two-sided $90\\%$ confidence interval for the true  mean $\\mu$ (of course we will know $\\mu$ because we will define it for sampling, but for the sake of the exercise we will pretend otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(999)\n",
    "\n",
    "x <- rnorm(250, mean = 100, sd = 15)\n",
    "\n",
    "# Number of observations\n",
    "n <- length(x)\n",
    "# Sample mean\n",
    "xbar <- mean(x)\n",
    "# Sample variance\n",
    "s2 <- var(x)\n",
    "# Standard error of the mean (standard deviation of the sample mean distribution)\n",
    "se <- sqrt(s2 / n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence interval we are trying to compute is two-sided and we want to have the confidence level of $90\\%$.\n",
    "Hence, we need to distribute $5\\%$ of the error on each side. Thus, we need to determine what is the\n",
    "$95\\%$ quantile of the standard normal distribution $q^{0.95}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q95 <- qnorm(.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci90 <- xbar + c(-1, 1) * se * q95\n",
    "ci90\n",
    "\n",
    "# Note the c(-1, 1) term. It is used to add and subtract `se * q95` at the same time\n",
    "# to produce a range around `xbar`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our confidence interval contains the true mean $\\mu = 100$. But is this always the case?\n",
    "We know from the theory that a confidence interval should contain the true parameter with rate $1 - \\alpha$,\n",
    "that is, over multiple replications of a study $1 - \\alpha$ is the fraction of experiments that yielded \n",
    "confidence interval overlapping with the true parameter value.\n",
    "\n",
    "Now we will show this using simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(303)\n",
    "\n",
    "# True mean\n",
    "mu <- 100\n",
    "# Number of replications\n",
    "R <- 1000\n",
    "# Counter for counting intervals containing the true mean\n",
    "counter <- 0\n",
    "# Significance level (confidence is 1 - alpha)\n",
    "alpha <- 0.10\n",
    "\n",
    "# Loop and run the experiment multiple times\n",
    "for (i in 1:R) {\n",
    "    data <- rnorm(250, mean = mu, sd = 15)\n",
    "    xbar <- mean(data)\n",
    "    se   <- sqrt(var(data) / length(data))\n",
    "    ci90 <- xbar + c(-1, 1) * se * qnorm(1 - alpha / 2) # alpha / 2 because this is a two-sided CI\n",
    "    if (ci90[1] <= mu && ci90[2] >= mu) {\n",
    "        counter <- counter + 1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Fraction of confidence intervals containing the mean\n",
    "# (clearly it is very close to 90%)\n",
    "counter / R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing\n",
    "\n",
    "Now we will conduct a simple $z$ test for the difference between two mean. A $z$ test is a generic term\n",
    "for a test that uses a test statistic which is distributed with the standard normal distribution.\n",
    "\n",
    "The data we will use is normal that is why we know for sure that distributions of sample means in two\n",
    "groups will be normal too and thus also the distribution of their difference will be normal.\n",
    "\n",
    "We use the following hypotheses:\n",
    "\n",
    "$$\n",
    "H_0: \\mu_1 = \\mu_2\n",
    "$$\n",
    "$$\n",
    "H_1: \\mu_1 \\neq \\mu_2\n",
    "$$\n",
    "\n",
    "Moreover, we use $\\alpha = 0.05$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(101)\n",
    "\n",
    "# Significance level\n",
    "alpha <- 0.05\n",
    "\n",
    "# Known true variances\n",
    "sigma2_1 <- 2\n",
    "sigma2_2 <- 3\n",
    "\n",
    "x1 <- rnorm(100, mean = 10, sd = sigma2_1)\n",
    "x2 <- rnorm(80, mean = 11, sd = sigma2_2)\n",
    "\n",
    "n1 <- length(x1)\n",
    "n2 <- length(x2)\n",
    "\n",
    "xbar1 <- mean(x1)\n",
    "xbar2 <- mean(x2)\n",
    "\n",
    "diff  <- xbar1 - xbar2\n",
    "\n",
    "# Standard error of the difference\n",
    "se_diff <- sqrt(sigma2_1 / n1 + sigma2_2 / n2)\n",
    "\n",
    "# Test statistic (under H_0 we have that z ~ Norm(0, 1))\n",
    "z <- diff / se_diff\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejection region boundaries based on alpha = 0.05\n",
    "# We divide alpha / 2 because the test is two-sided\n",
    "rejection_boundaries <- c(-1, 1) * qnorm(1 - alpha / 2)\n",
    "rejection_boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the test statistic does land in one of the rejection regions. So we can reject the null hypothesis.\n",
    "We can also get a more finely-grained result by computing the corresponding $p$-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * pnorm(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, we can also get a better, interval estimate of the effect by computing the confidence\n",
    "interval for the difference between the sample means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff + c(-1, 1) * se_diff * qnorm(1 - alpha / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare our results with an implementation of a simple $z$ test provided in `BSDA` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSDA::z.test(x1, x2, sigma.x = sqrt(sigma2_1), sigma.y = sqrt(sigma2_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, all results are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end this notebook with a simple visualization of the meaning of a test statistic.\n",
    "Below we plot the distribution of $z$ under the assumption of the null hypothesis $H_0$.\n",
    "\n",
    "The red dot denotes the true value of the observed test statistic $z \\approx -3.24$. \n",
    "The green dot is an example of what happens when the absolute value of a test statistic is small.\n",
    "This happens when the data we observe is highly likely under the assumption of $H_0$.\n",
    "Only when it is extremely unlikely to be osberved if $H_0$, we can reject the null hypothesis\n",
    "assume that the alternative applies instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data = data.frame(x = c(-4, 4)), aes(x = x)) +\n",
    "    stat_function(fun = dnorm, n = 200) +\n",
    "    geom_point(data = data.frame(x = z, y = dnorm(z)), aes(x = x, y = y), col = \"red\", shape = 19, size = 12) +\n",
    "    geom_point(data = data.frame(x = .5, y = dnorm(.5)), aes(x = x, y = y), col = \"darkgreen\", shape = 19, size = 12) +\n",
    "    xlab(TeX(\"$\\\\bar{D}$\")) +\n",
    "    ylab(\"Probability density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
